"""
DiffPlace Pickle Dataset

Efficiently loads placement data from pickle files generated by synthetic data generation module.
Optimized for large datasets - only loads pickle files on demand, with optional caching.

Data format expected:
    Each .pickle file contains a list of tuples: [(positions, PyG_Data), ...]
    - positions: torch.Tensor (V, 2) - macro center coordinates
    - PyG_Data: torch_geometric.data.Data with:
        - x: (V, 2) - macro sizes (width, height)
        - edge_index: (2, E) - graph connectivity
        - edge_attr: (E, 4) - pin offsets
        - is_ports: (V,) - boolean mask for fixed nodes
"""

import os
import pickle
import glob
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
from collections import OrderedDict

import torch
from torch.utils.data import Dataset
from torch_geometric.data import Data


class LRUCache:
    """Simple LRU cache for pickle files."""
    
    def __init__(self, max_size: int = 5):
        self.max_size = max_size
        self.cache: OrderedDict = OrderedDict()
    
    def get(self, key: str) -> Optional[Any]:
        if key in self.cache:
            # Move to end (most recently used)
            self.cache.move_to_end(key)
            return self.cache[key]
        return None
    
    def put(self, key: str, value: Any):
        if key in self.cache:
            self.cache.move_to_end(key)
        else:
            if len(self.cache) >= self.max_size:
                # Remove oldest
                self.cache.popitem(last=False)
            self.cache[key] = value


class DiffPlacePickleDataset(Dataset):
    """
    Dataset for loading placement data from pickle files.
    
    Features:
    - Lazy loading: Only loads pickle files when needed
    - LRU caching: Keeps recently used files in memory
    - Index mapping: Maps global index to (file, local_index)
    - Automatic train/val split based on file order
    - Rotation augmentation: Random rotation of macros with ground truth labels
    
    Args:
        data_dir: Directory containing .pickle files
        split: 'train' or 'val' (determines which files to use)
        train_ratio: Fraction of files used for training (default 0.9)
        cache_size: Number of pickle files to keep in memory (default 5)
        transform: Optional transform to apply to samples
        samples_per_pickle: Expected samples per pickle (for pre-counting, default 100)
        rotation_augment: Whether to apply random rotation augmentation
        rotation_prob: Probability of rotating each macro (default 0.5)
    """
    
    def __init__(
        self,
        data_dir: str,
        split: str = "train",
        train_ratio: float = 0.9,
        cache_size: int = 5,
        transform = None,
        samples_per_pickle: int = 100,
        verbose: bool = True,
        rotation_augment: bool = False,
        rotation_prob: float = 0.5,
    ):
        self.data_dir = Path(data_dir)
        self.split = split
        self.train_ratio = train_ratio
        self.transform = transform
        self.verbose = verbose
        self.rotation_augment = rotation_augment
        self.rotation_prob = rotation_prob
        
        # Find all pickle files
        self.all_pickle_files = sorted(glob.glob(str(self.data_dir / "*.pickle")))
        
        if len(self.all_pickle_files) == 0:
            raise ValueError(f"No .pickle files found in {data_dir}")
        
        if verbose:
            print(f"[DiffPlacePickleDataset] Found {len(self.all_pickle_files)} pickle files in {data_dir}")
        
        # Split files into train/val
        num_train_files = int(len(self.all_pickle_files) * train_ratio)
        if split == "train":
            self.pickle_files = self.all_pickle_files[:num_train_files]
        else:  # val
            self.pickle_files = self.all_pickle_files[num_train_files:]
        
        if len(self.pickle_files) == 0:
            raise ValueError(f"No files for split '{split}' with train_ratio={train_ratio}")
        
        if verbose:
            print(f"[DiffPlacePickleDataset] Using {len(self.pickle_files)} files for {split}")
        
        # Build index mapping
        self.index_mapping = []  # List of (file_idx, local_idx)
        self.file_sample_counts = []  # Number of samples per file
        
        self._build_index_mapping(samples_per_pickle)
        
        # LRU cache for loaded pickle files
        self.cache = LRUCache(max_size=cache_size)
        
        if verbose:
            print(f"[DiffPlacePickleDataset] Total samples: {len(self.index_mapping)}")
    
    def _build_index_mapping(self, samples_per_pickle: int):
        """Build mapping from global index to (file_idx, local_idx)."""
        # First, try to get actual counts by loading first file
        try:
            first_data = self._load_pickle(self.pickle_files[0])
            actual_samples = len(first_data)
            samples_per_pickle = actual_samples
            if self.verbose:
                print(f"[DiffPlacePickleDataset] Detected {samples_per_pickle} samples per pickle")
        except Exception as e:
            if self.verbose:
                print(f"[DiffPlacePickleDataset] Could not detect samples per pickle, using default {samples_per_pickle}")
        
        # Build mapping assuming uniform distribution
        for file_idx, file_path in enumerate(self.pickle_files):
            self.file_sample_counts.append(samples_per_pickle)
            for local_idx in range(samples_per_pickle):
                self.index_mapping.append((file_idx, local_idx))
    
    def _load_pickle(self, file_path: str) -> List:
        """Load pickle file."""
        with open(file_path, "rb") as f:
            return pickle.load(f)
    
    def _get_pickle_data(self, file_idx: int) -> List:
        """Get pickle data with caching."""
        file_path = self.pickle_files[file_idx]
        
        # Check cache
        cached = self.cache.get(file_path)
        if cached is not None:
            return cached
        
        # Load and cache
        data = self._load_pickle(file_path)
        self.cache.put(file_path, data)
        return data
    
    def __len__(self) -> int:
        return len(self.index_mapping)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Data]:
        """
        Get a sample by global index.
        
        Returns:
            positions: (V, 2) tensor of macro positions
            data: PyG Data object with graph structure
        """
        if idx < 0 or idx >= len(self.index_mapping):
            raise IndexError(f"Index {idx} out of range [0, {len(self.index_mapping)})")
        
        file_idx, local_idx = self.index_mapping[idx]
        
        # Load pickle data
        pickle_data = self._get_pickle_data(file_idx)
        
        # Handle case where actual file has fewer samples than expected
        if local_idx >= len(pickle_data):
            # Wrap around
            local_idx = local_idx % len(pickle_data)
        
        # Get sample
        sample = pickle_data[local_idx]
        
        # Unpack tuple
        if isinstance(sample, tuple) and len(sample) == 2:
            positions, data = sample
        else:
            raise ValueError(f"Expected tuple (positions, data), got {type(sample)}")
        
        # Ensure positions is float tensor
        if not torch.is_tensor(positions):
            positions = torch.tensor(positions, dtype=torch.float32)
        else:
            positions = positions.float()
        
        # Clone data to avoid modifying cached version
        data = self._clone_data(data)
        
        # Add positions as .pos attribute for VectorGNN
        data.pos = positions.clone()
        
        # Validate data format
        self._validate_data(data, positions)
        
        # Apply rotation augmentation if enabled
        # This creates ground truth rotation labels for training
        rotation_gt = None
        if self.rotation_augment:
            positions, data, rotation_gt = self._apply_rotation_augmentation(positions, data)
        
        # Apply transform if provided
        # Note: Transform may add batch dimension, so we handle it
        if self.transform is not None:
            positions_before = positions.clone()
            positions, data = self.transform(positions, data)
            
            # Ensure positions is 2D (V, 2) - transform adds batch dimension (1, V, 2)
            if positions.dim() == 3:
                if positions.shape[0] == 1:
                    positions = positions.squeeze(0)  # Remove batch dimension
                else:
                    # If batch size > 1, take first element
                    positions = positions[0]
            elif positions.dim() != 2:
                raise ValueError(f"Unexpected positions shape after transform: {positions.shape}")
        
        # Final validation: positions must be 2D (V, 2) or (V, 3) with rotation
        if rotation_gt is not None:
            # Add rotation ground truth as third channel
            positions = torch.cat([positions, rotation_gt.unsqueeze(-1)], dim=-1)  # (V, 3)
            assert positions.dim() == 2 and positions.shape[1] == 3, \
                f"positions with rotation must be (V, 3), got {positions.shape}"
        else:
            assert positions.dim() == 2 and positions.shape[1] == 2, \
                f"positions must be (V, 2), got {positions.shape}"
        
        return positions, data
    
    def _apply_rotation_augmentation(
        self, 
        positions: torch.Tensor, 
        data: Data
    ) -> Tuple[torch.Tensor, Data, torch.Tensor]:
        """
        Apply random rotation augmentation to macros.
        
        For each macro:
        1. With probability `rotation_prob`, mark it as rotated
        2. Swap width and height in data.x (node features/sizes)
        3. Create ground truth rotation labels (1 if rotated, 0 if not)
        
        Args:
            positions: (V, 2) tensor of macro positions
            data: PyG Data object with x attribute containing sizes (w, h)
            
        Returns:
            positions: (V, 2) unchanged positions
            data: Modified data with swapped sizes for rotated macros
            rotation_gt: (V,) tensor of rotation ground truth (float: 0.0 or 1.0)
        """
        V = positions.shape[0]
        
        # Generate random rotation mask
        # rot_mask[i] = True means macro i should be rotated 90Â°
        rot_mask = torch.rand(V) < self.rotation_prob
        
        # Don't rotate ports/fixed nodes if they exist
        if hasattr(data, 'is_ports') and data.is_ports is not None:
            rot_mask = rot_mask & ~data.is_ports
        if hasattr(data, 'is_fixed') and data.is_fixed is not None:
            rot_mask = rot_mask & ~data.is_fixed
        
        # Swap width and height for rotated macros in data.x (sizes)
        if hasattr(data, 'x') and data.x is not None:
            sizes = data.x.clone()  # (V, 2) - (width, height)
            # For rotated macros: (w, h) -> (h, w)
            swapped_sizes = sizes[:, [1, 0]]  # Swap columns
            data.x = torch.where(
                rot_mask.unsqueeze(-1).expand(-1, 2),
                swapped_sizes,
                sizes
            )
        
        # Also swap in node_sizes if it exists
        if hasattr(data, 'node_sizes') and data.node_sizes is not None:
            node_sizes = data.node_sizes.clone()
            swapped_node_sizes = node_sizes[:, [1, 0]]
            data.node_sizes = torch.where(
                rot_mask.unsqueeze(-1).expand(-1, 2),
                swapped_node_sizes,
                node_sizes
            )
        
        # Create rotation ground truth
        # Use float for compatibility with diffusion loss
        # r=1.0 if rotated, r=0.0 if not
        rotation_gt = rot_mask.float()  # (V,)
        
        return positions, data, rotation_gt
    
    def _clone_data(self, data: Data) -> Data:
        """Clone PyG Data object."""
        new_data = Data()
        for key in data.keys():
            value = data[key]
            if torch.is_tensor(value):
                setattr(new_data, key, value.clone())
            else:
                setattr(new_data, key, value)
        return new_data
    
    def _validate_data(self, data: Data, positions: torch.Tensor):
        """Validate data format for VectorGNN."""
        V = positions.shape[0]
        
        # Check positions shape
        assert positions.dim() == 2 and positions.shape[1] == 2, \
            f"positions must be (V, 2), got {positions.shape}"
        
        # Check node features (sizes)
        assert hasattr(data, 'x') and data.x is not None, \
            "data.x (node features) is required"
        assert data.x.shape == (V, 2), \
            f"data.x must be (V, 2), got {data.x.shape}"
        
        # Check edge_index
        assert hasattr(data, 'edge_index') and data.edge_index is not None, \
            "data.edge_index is required"
        assert data.edge_index.dim() == 2 and data.edge_index.shape[0] == 2, \
            f"edge_index must be (2, E), got {data.edge_index.shape}"
        
        # Ensure is_ports exists
        if not hasattr(data, 'is_ports') or data.is_ports is None:
            data.is_ports = torch.zeros(V, dtype=torch.bool)
    
    def get_sample_info(self, idx: int) -> Dict:
        """Get information about a sample without loading full data."""
        file_idx, local_idx = self.index_mapping[idx]
        return {
            "file_path": self.pickle_files[file_idx],
            "file_idx": file_idx,
            "local_idx": local_idx,
        }


class DiffPlaceDataLoader:
    """
    DataLoader wrapper for DiffPlacePickleDataset.
    
    Handles batching and provides interface compatible with training script.
    Supports optional rotation channel for 3D output (x, y, rotation_logit).
    """
    
    def __init__(
        self,
        train_dataset: DiffPlacePickleDataset,
        val_dataset: DiffPlacePickleDataset,
        train_batch_size: int = 16,
        val_batch_size: int = 1,
        device: str = "cuda",
        shuffle_train: bool = True,
        output_dim: int = 2,  # 2 for (x,y) or 3 for (x,y,rotation)
    ):
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.train_batch_size = train_batch_size
        self.val_batch_size = val_batch_size
        self.device = device
        self.shuffle_train = shuffle_train
        self.output_dim = output_dim
        
        self.train_indices = list(range(len(train_dataset)))
        self.val_indices = list(range(len(val_dataset)))
        
        self.train_idx = 0
        self.val_idx = 0
        
        self._display_cache = {"train": None, "val": None}
    
    def get_batch(self, split: str = "train") -> Tuple[torch.Tensor, Data]:
        """Get a batch of data.
        
        Returns:
            x: (B, V, output_dim) tensor - positions with optional rotation channel
            data: PyG Data object with graph structure
            
        If output_dim=3, a zero-initialized rotation channel is appended.
        This allows the model to learn rotation from scratch during training.
        """
        dataset = self.train_dataset if split == "train" else self.val_dataset
        batch_size = self.train_batch_size if split == "train" else self.val_batch_size
        
        if split == "train" and self.shuffle_train:
            idx = torch.randint(0, len(dataset), (1,)).item()
        else:
            if split == "train":
                idx = self.train_idx
                self.train_idx = (self.train_idx + 1) % len(dataset)
            else:
                idx = self.val_idx
                self.val_idx = (self.val_idx + 1) % len(dataset)
        
        # Get single sample
        positions, data = dataset[idx]
        
        # Ensure positions is 2D - handle case where transform added batch dimension
        if positions.dim() == 3:
            positions = positions.squeeze(0)  # Remove batch dimension if present
        
        # Handle rotation augmentation case: positions may already have 3 channels
        # from DiffPlacePickleDataset with rotation_augment=True
        pos_dim = positions.shape[-1]
        
        if pos_dim == 3:
            # Dataset already provides rotation ground truth (from augmentation)
            # positions is (V, 3) with [x, y, rotation_gt]
            if self.output_dim == 2:
                # If we don't want rotation, strip the rotation channel
                positions = positions[:, :2]
            # If output_dim=3, keep as is
        elif pos_dim == 2:
            # Standard 2D positions
            if self.output_dim == 3:
                # Append rotation channel (initialized to 0 for no rotation)
                V = positions.shape[0]
                rotation_channel = torch.zeros(V, 1, dtype=positions.dtype)
                positions = torch.cat([positions, rotation_channel], dim=-1)  # (V, 3)
        else:
            raise ValueError(f"Unexpected positions dim: {pos_dim}")
        
        assert positions.dim() == 2 and positions.shape[1] == self.output_dim, \
            f"positions must be (V, {self.output_dim}), got {positions.shape}"
        
        # Expand for batch (all samples in batch use same graph structure)
        x = positions.unsqueeze(0).expand(batch_size, -1, -1).clone()
        
        # Move to device
        x = x.to(self.device)
        data = data.to(self.device)
        
        return x, data
    
    def get_display_batch(self, num_samples: int, split: str = "val") -> Tuple[torch.Tensor, Data]:
        """Get a fixed batch for visualization."""
        if self._display_cache[split] is None:
            self._display_cache[split] = self.get_batch(split)
        
        x, data = self._display_cache[split]
        return x[:num_samples], data
    
    def get_train_size(self) -> int:
        return len(self.train_dataset)
    
    def get_val_size(self) -> int:
        return len(self.val_dataset)


def create_dataloaders_from_pickle(
    data_dir: str,
    train_batch_size: int = 16,
    val_batch_size: int = 1,
    train_ratio: float = 0.9,
    cache_size: int = 5,
    device: str = "cuda",
    transform = None,
    output_dim: int = 2,  # 2 for (x,y) or 3 for (x,y,rotation)
    rotation_augment: bool = False,  # Enable rotation augmentation for training
    rotation_prob: float = 0.5,  # Probability of rotating each macro
) -> DiffPlaceDataLoader:
    """
    Create train/val dataloaders from pickle directory.
    
    Args:
        data_dir: Directory containing .pickle files
        train_batch_size: Batch size for training
        val_batch_size: Batch size for validation
        train_ratio: Fraction of files for training
        cache_size: Number of pickle files to cache
        device: Device to use
        transform: Optional transform
        output_dim: Output dimension (2 for position only, 3 for position + rotation)
        rotation_augment: Whether to apply random rotation augmentation (train only)
        rotation_prob: Probability of rotating each macro (when augmentation enabled)
    
    Returns:
        DiffPlaceDataLoader with train/val datasets
    """
    train_dataset = DiffPlacePickleDataset(
        data_dir=data_dir,
        split="train",
        train_ratio=train_ratio,
        cache_size=cache_size,
        transform=transform,
        verbose=True,
        rotation_augment=rotation_augment,  # Only augment training data
        rotation_prob=rotation_prob,
    )
    
    val_dataset = DiffPlacePickleDataset(
        data_dir=data_dir,
        split="val",
        train_ratio=train_ratio,
        cache_size=cache_size,
        transform=transform,
        verbose=True,
        rotation_augment=False,  # Never augment validation data
        rotation_prob=0.0,
    )
    
    return DiffPlaceDataLoader(
        train_dataset=train_dataset,
        val_dataset=val_dataset,
        train_batch_size=train_batch_size,
        val_batch_size=val_batch_size,
        device=device,
        shuffle_train=True,
        output_dim=output_dim,
    )

